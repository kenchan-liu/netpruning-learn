{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24e94a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "439a18b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square conv kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5x5 image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, int(x.nelement() / x.shape[0]))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = LeNet().to(device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5901968f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('weight', Parameter containing:\n",
      "tensor([[[[ 0.0319, -0.0283, -0.0410],\n",
      "          [-0.1058,  0.0628,  0.1391],\n",
      "          [ 0.2139,  0.1283, -0.0265]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3245, -0.2847,  0.1321],\n",
      "          [ 0.0051, -0.0475, -0.0135],\n",
      "          [-0.3256, -0.2450,  0.1750]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2834, -0.0207,  0.1597],\n",
      "          [ 0.1738,  0.0266, -0.3305],\n",
      "          [ 0.0215,  0.0884, -0.0436]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2800,  0.2257, -0.0656],\n",
      "          [ 0.0157, -0.2003, -0.0971],\n",
      "          [ 0.0795, -0.1221,  0.1232]]],\n",
      "\n",
      "\n",
      "        [[[-0.0522, -0.1284, -0.1628],\n",
      "          [ 0.0359,  0.1182,  0.1768],\n",
      "          [ 0.0098,  0.3059, -0.0190]]],\n",
      "\n",
      "\n",
      "        [[[-0.1305,  0.2425, -0.2519],\n",
      "          [ 0.3133,  0.1959,  0.2756],\n",
      "          [-0.2196,  0.0205,  0.0363]]]], device='cuda:0', requires_grad=True)), ('bias', Parameter containing:\n",
      "tensor([ 0.3270,  0.0763,  0.1773, -0.0414, -0.2483, -0.1971], device='cuda:0',\n",
      "       requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "module = model.conv1\n",
    "print(list(module.named_parameters()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "896b6fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(list(module.named_buffers()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d35cb0be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prune.random_unstructured(module, name=\"weight\", amount=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2e0dc4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bias', Parameter containing:\n",
      "tensor([ 0.3270,  0.0763,  0.1773, -0.0414, -0.2483, -0.1971], device='cuda:0',\n",
      "       requires_grad=True)), ('weight_orig', Parameter containing:\n",
      "tensor([[[[ 0.0319, -0.0283, -0.0410],\n",
      "          [-0.1058,  0.0628,  0.1391],\n",
      "          [ 0.2139,  0.1283, -0.0265]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3245, -0.2847,  0.1321],\n",
      "          [ 0.0051, -0.0475, -0.0135],\n",
      "          [-0.3256, -0.2450,  0.1750]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2834, -0.0207,  0.1597],\n",
      "          [ 0.1738,  0.0266, -0.3305],\n",
      "          [ 0.0215,  0.0884, -0.0436]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2800,  0.2257, -0.0656],\n",
      "          [ 0.0157, -0.2003, -0.0971],\n",
      "          [ 0.0795, -0.1221,  0.1232]]],\n",
      "\n",
      "\n",
      "        [[[-0.0522, -0.1284, -0.1628],\n",
      "          [ 0.0359,  0.1182,  0.1768],\n",
      "          [ 0.0098,  0.3059, -0.0190]]],\n",
      "\n",
      "\n",
      "        [[[-0.1305,  0.2425, -0.2519],\n",
      "          [ 0.3133,  0.1959,  0.2756],\n",
      "          [-0.2196,  0.0205,  0.0363]]]], device='cuda:0', requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "print(list(module.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08029711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.0000, -0.0000, -0.0000],\n",
      "          [-0.1058,  0.0628,  0.1391],\n",
      "          [ 0.2139,  0.1283, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3245, -0.2847,  0.1321],\n",
      "          [ 0.0000, -0.0475, -0.0000],\n",
      "          [-0.3256, -0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2834, -0.0207,  0.1597],\n",
      "          [ 0.1738,  0.0266, -0.3305],\n",
      "          [ 0.0215,  0.0884, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2800,  0.2257, -0.0656],\n",
      "          [ 0.0000, -0.2003, -0.0000],\n",
      "          [ 0.0000, -0.1221,  0.1232]]],\n",
      "\n",
      "\n",
      "        [[[-0.0522, -0.1284, -0.1628],\n",
      "          [ 0.0359,  0.1182,  0.1768],\n",
      "          [ 0.0098,  0.0000, -0.0190]]],\n",
      "\n",
      "\n",
      "        [[[-0.1305,  0.0000, -0.2519],\n",
      "          [ 0.3133,  0.0000,  0.2756],\n",
      "          [-0.2196,  0.0000,  0.0363]]]], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(module.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a922657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([(2, <torch.nn.utils.prune.RandomUnstructured object at 0x0000015834064040>)])\n"
     ]
    }
   ],
   "source": [
    "print(module._forward_pre_hooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2aa571a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prune.l1_unstructured(module, name=\"bias\", amount=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "554784f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('weight_orig', Parameter containing:\n",
      "tensor([[[[ 0.0319, -0.0283, -0.0410],\n",
      "          [-0.1058,  0.0628,  0.1391],\n",
      "          [ 0.2139,  0.1283, -0.0265]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3245, -0.2847,  0.1321],\n",
      "          [ 0.0051, -0.0475, -0.0135],\n",
      "          [-0.3256, -0.2450,  0.1750]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2834, -0.0207,  0.1597],\n",
      "          [ 0.1738,  0.0266, -0.3305],\n",
      "          [ 0.0215,  0.0884, -0.0436]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2800,  0.2257, -0.0656],\n",
      "          [ 0.0157, -0.2003, -0.0971],\n",
      "          [ 0.0795, -0.1221,  0.1232]]],\n",
      "\n",
      "\n",
      "        [[[-0.0522, -0.1284, -0.1628],\n",
      "          [ 0.0359,  0.1182,  0.1768],\n",
      "          [ 0.0098,  0.3059, -0.0190]]],\n",
      "\n",
      "\n",
      "        [[[-0.1305,  0.2425, -0.2519],\n",
      "          [ 0.3133,  0.1959,  0.2756],\n",
      "          [-0.2196,  0.0205,  0.0363]]]], device='cuda:0', requires_grad=True)), ('bias_orig', Parameter containing:\n",
      "tensor([ 0.3270,  0.0763,  0.1773, -0.0414, -0.2483, -0.1971], device='cuda:0',\n",
      "       requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "print(list(module.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83e51ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('weight_mask', tensor([[[[0., 0., 0.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.],\n",
      "          [0., 1., 0.],\n",
      "          [1., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.],\n",
      "          [0., 1., 0.],\n",
      "          [0., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 0., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 0., 1.],\n",
      "          [1., 0., 1.],\n",
      "          [1., 0., 1.]]]], device='cuda:0')), ('bias_mask', tensor([1., 0., 0., 0., 1., 1.], device='cuda:0'))]\n"
     ]
    }
   ],
   "source": [
    "print(list(module.named_buffers()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07a2e2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.3270,  0.0000,  0.0000, -0.0000, -0.2483, -0.1971], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(module.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5921770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3245, -0.2847,  0.1321],\n",
      "          [ 0.0000, -0.0475, -0.0000],\n",
      "          [-0.3256, -0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2834, -0.0207,  0.1597],\n",
      "          [ 0.1738,  0.0266, -0.3305],\n",
      "          [ 0.0215,  0.0884, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000, -0.0000],\n",
      "          [ 0.0000, -0.0000, -0.0000],\n",
      "          [ 0.0000, -0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000, -0.0000, -0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.1305,  0.0000, -0.2519],\n",
      "          [ 0.3133,  0.0000,  0.2756],\n",
      "          [-0.2196,  0.0000,  0.0363]]]], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "prune.ln_structured(module, name=\"weight\", amount=0.5, n=2, dim=0)\n",
    "\n",
    "# As we can verify, this will zero out all the connections corresponding to\n",
    "# 50% (3 out of 6) of the channels, while preserving the action of the\n",
    "# previous mask.\n",
    "print(module.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05145662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['conv1.weight_mask', 'conv2.weight_mask', 'fc1.weight_mask', 'fc2.weight_mask', 'fc3.weight_mask'])\n"
     ]
    }
   ],
   "source": [
    "new_model = LeNet()\n",
    "for name, module in new_model.named_modules():\n",
    "    # prune 20% of connections in all 2D-conv layers\n",
    "    if isinstance(module, torch.nn.Conv2d):\n",
    "        prune.l1_unstructured(module, name='weight', amount=0.2)\n",
    "    # prune 40% of connections in all linear layers\n",
    "    elif isinstance(module, torch.nn.Linear):\n",
    "        prune.l1_unstructured(module, name='weight', amount=0.4)\n",
    "\n",
    "print(dict(new_model.named_buffers()).keys())  # to verify that all masks exist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "002aecb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity in conv1.weight: 1.85%\n",
      "Sparsity in conv2.weight: 6.83%\n",
      "Sparsity in fc1.weight: 22.11%\n",
      "Sparsity in fc2.weight: 12.08%\n",
      "Sparsity in fc3.weight: 9.17%\n",
      "Global sparsity: 20.00%\n"
     ]
    }
   ],
   "source": [
    "model = LeNet()\n",
    "\n",
    "parameters_to_prune = (\n",
    "    (model.conv1, 'weight'),\n",
    "    (model.conv2, 'weight'),\n",
    "    (model.fc1, 'weight'),\n",
    "    (model.fc2, 'weight'),\n",
    "    (model.fc3, 'weight'),\n",
    ")\n",
    "\n",
    "prune.global_unstructured(\n",
    "    parameters_to_prune,\n",
    "    pruning_method=prune.L1Unstructured,\n",
    "    amount=0.2,\n",
    ")\n",
    "print(\n",
    "    \"Sparsity in conv1.weight: {:.2f}%\".format(\n",
    "        100. * float(torch.sum(model.conv1.weight == 0))\n",
    "        / float(model.conv1.weight.nelement())\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Sparsity in conv2.weight: {:.2f}%\".format(\n",
    "        100. * float(torch.sum(model.conv2.weight == 0))\n",
    "        / float(model.conv2.weight.nelement())\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Sparsity in fc1.weight: {:.2f}%\".format(\n",
    "        100. * float(torch.sum(model.fc1.weight == 0))\n",
    "        / float(model.fc1.weight.nelement())\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Sparsity in fc2.weight: {:.2f}%\".format(\n",
    "        100. * float(torch.sum(model.fc2.weight == 0))\n",
    "        / float(model.fc2.weight.nelement())\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Sparsity in fc3.weight: {:.2f}%\".format(\n",
    "        100. * float(torch.sum(model.fc3.weight == 0))\n",
    "        / float(model.fc3.weight.nelement())\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Global sparsity: {:.2f}%\".format(\n",
    "        100. * float(\n",
    "            torch.sum(model.conv1.weight == 0)\n",
    "            + torch.sum(model.conv2.weight == 0)\n",
    "            + torch.sum(model.fc1.weight == 0)\n",
    "            + torch.sum(model.fc2.weight == 0)\n",
    "            + torch.sum(model.fc3.weight == 0)\n",
    "        )\n",
    "        / float(\n",
    "            model.conv1.weight.nelement()\n",
    "            + model.conv2.weight.nelement()\n",
    "            + model.fc1.weight.nelement()\n",
    "            + model.fc2.weight.nelement()\n",
    "            + model.fc3.weight.nelement()\n",
    "        )\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ae02fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FooBarPruningMethod(prune.BasePruningMethod):\n",
    "    \"\"\"Prune every other entry in a tensor\n",
    "    \"\"\"\n",
    "    PRUNING_TYPE = 'unstructured'\n",
    "\n",
    "    def compute_mask(self, t, default_mask):\n",
    "        mask = default_mask.clone()\n",
    "        mask.view(-1)[::2] = 0\n",
    "        return mask\n",
    "def foobar_unstructured(module, name):\n",
    "    \"\"\"Prunes tensor corresponding to parameter called `name` in `module`\n",
    "    by removing every other entry in the tensors.\n",
    "    Modifies module in place (and also return the modified module)\n",
    "    by:\n",
    "    1) adding a named buffer called `name+'_mask'` corresponding to the\n",
    "    binary mask applied to the parameter `name` by the pruning method.\n",
    "    The parameter `name` is replaced by its pruned version, while the\n",
    "    original (unpruned) parameter is stored in a new parameter named\n",
    "    `name+'_orig'`.\n",
    "\n",
    "    Args:\n",
    "        module (nn.Module): module containing the tensor to prune\n",
    "        name (string): parameter name within `module` on which pruning\n",
    "                will act.\n",
    "\n",
    "    Returns:\n",
    "        module (nn.Module): modified (i.e. pruned) version of the input\n",
    "            module\n",
    "\n",
    "    Examples:\n",
    "        >>> m = nn.Linear(3, 4)\n",
    "        >>> foobar_unstructured(m, name='bias')\n",
    "    \"\"\"\n",
    "    FooBarPruningMethod.apply(module, name)\n",
    "    return module\n",
    "model = LeNet()\n",
    "foobar_unstructured(model.fc3, name='bias')\n",
    "\n",
    "print(model.fc3.bias_mask)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
